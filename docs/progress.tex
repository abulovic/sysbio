\documentclass[12pt,a4paper,titlepage, fullpage]{article}
\usepackage{hyperref}
\usepackage[pdftex]{graphicx}
\bibliographystyle{plain}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\usepackage{url}
\usepackage[nottoc]{tocbibind}
\begin{document}

\input{./title.tex}
\begin{abstract}
The increase in the use of theoretical mathematical models to describe biological systems has led to an increasing need for computational tools to assist in the process of constructing those models and estimating their parameters from available experimental data. Although there is a rich literature on parameter estimation using a number of different techniques, very few attempts have been made to produce computational tools that systematically attack the parameter estimation problem. From those, almost all of them attempt to reproduce experimental data, disregarding qualitative features of the systems and other requirements we might have from the model arising from the dynamic behaviour of such systems as they evolve or respond to external or internal stimuli.

The aim of this project it to produce a computational tool for automatic parameter estimation in generic dynamic biological systems taking into account the dynamic behaviour of such systems.
\end{abstract}
\tableofcontents
\newpage
\section{Problem and Project goals}
Although mathematical modeling for biological systems is not a new topic, with the advent of microarray experiments that enabled us to take measurements of the expression levels of a big number of genes at different time points, there has been a big grow in the attempts to mathematically capture the behaviour of such systems. These measurements led to the discovery of common patterns and networks in cell behaviour. Increasingly complex models have been employed to describe the behaviour of such networks.  The use of models in this case is beneficial as they provide a great intuition and increased understanding into the dynamic nature of such systems and can even uncover and predict new behaviour which can lead to experimental confirmation. These models are often a system of Ordinary Differential Equations (ODEs) which are the natural way to capture dynamic and changing behaviour. As the complexity of these models grew the problem of estimating the parameters of these models, in this case primarily rate constants and kinetic parameters, became a major task for modelers as those parameters are often infeasible to experimentally measure. This fact along with the noisy and often scarce data made people resort to manual search of parameter space and/or mathematical techniques to assist in the task. \\
\noindent
\\
The last few years and with the rapid technological advancements, the computational cost associated with such techniques has fallen and there have been some attempts to automate this process with the production of computational tools that tackle the parameter estimation problem using mathematical methods borrowed from other fields. Unlike other fields however the requirements of models of biological systems are greater than just a simple reproduction of experimental data. These systems have qualitative features that are often very important and their behaviour changes as they evolve or respond to stimuli. If the proposed model does not take into account such behaviour then the model does not capture the precise behaviour and although it can sometimes be useful,  it is incomplete. The main goal of this project is the production of a computational tool that systematically attacks the problem of parameter estimation by automating the estimation process using mathematical methods. This tool will take into account the dynamic behaviour of biological systems and use these criteria in the parameter selection process. This new aspect will make the tool more powerful and the models produced more complete and closer to the true behaviour as exhibited in nature. I believe that mathematical models that capture all aspects of these systems will increase the confidence in modeling and the use of mathematical tools in biological research just like they are being used successfully in other scientific disciplines such as Physics.

\section{Background}
Recent advances in recombinant DNA and microarray technology have led to greater understanding of the networks that govern different cell processes. In these networks a number of different genes and proteins interact to carry out a biochemical process. Examples of well studied networks are metabolic pathways and circadian oscillators\cite{bass2010circadian}. The traditional way to describe these networks is by means of diagrams that show the signals and interaction between entities (genes, proteins). As these systems grow in complexity the diagrammatic way of describing the system is increasingly proved to be a poor way to do it as it does not give any intuition into the inner workings of the system nor does it capture the dynamic nature that such systems exhibit. Moreover as the complexity of the network grows it become increasingly difficult to predict the future behaviour of the system especially quantitatively. The advantages and the need for using  quantitative mathematical models to describe such systems has been recognised and the perception of their importance is growing\cite{lazebnik2002can}. Also the number of attempts to model systems that are thought to be well understood like circadian oscillators is ever increasing\cite{becker2004modeling, mirsky2009model}. Chemical kinetic laws such as the Law of mass-action or the Michaelis-Menten kinetics can be easily translated to simple systems of ODEs to construct simple components or commonly found patterns in biochemical networks such as switches, buzzers, blinkers\cite{tyson2003sniffers} the inspiration for the decomposition into electronic-like components coming from the resemblance that these networks show at the systems level with electronic circuits. By combining these simple motifs more complex networks can be built. Although the underlying behaviour at the molecular level is highly stochastic the models are deterministic systems of ODEs because the underlying stochasticity gives rise to deterministic behaviour at the systems level.\\
\noindent
\\
A typical systems can be described with a set of ODEs like so: 
$
\dot \mathbf{x} = \mathbf{f}(\mathbf{x}, t, \mathbf{ \theta })
$. 
Vector $\mathbf{x}$ is usually functions describing the change of the concentration of a substance (like mRNA, protein etc.) over time with $\mathbf{\theta}$ being the parameter vector. And although the construction of such models can be done by using simple laws (law of mass-action, Michaelis-Menten kinetics) or from just knowledge of the behaviour of the system in question, finding the parameters $\mathbf{\theta}$ that will make these systems behave according to observations is an equally if not more difficult task since experimentally measuring these parameters like rate constants can be next to impossible. The task therefore becomes from a set of observations over time $\mathbf{Y} = \{\mathbf{y}_{t_{1}}, \mathbf{y}_{t_{1}}, \dots, \mathbf{y}_{t_{n}}\} $ to find the parameter vector $\mathbf{\theta}^*$ such that the distance between the simulated dataset from $f(\mathbf{x}, t, \theta^*)$ and the actual dataset $\mathbf{Y}$ is minimum. This is a common formulation of the problem of the inverse problem which reduces the problem to an optimisation problem which is a well studied area\cite{gonze2011modeling}. Common local and global optimisation techniques have been used in this area as well\cite{moles2003parameter}.\\
\noindent
\\
Another way to look at the problem is from a statistical/probabilistic point of view. The goal in this case is to increase the likelihood $L(\theta) = f(Y|\theta)$ where Y are observations and $\theta$ is the parameter values\cite{filippi2011optimal}. Then the problem becomes to find the values of parameters $\theta$ that maximise the likelihood function $L(\theta)$. Maximum likelihood estimation is again a well studied area and techniques used in other areas have been employed in this particular case as well.%cite!!! 
Other statistical methods have also been employed to tackle this problem, like Bayesian inference techniques. The traditional Bayesian inference in this case becomes $\pi(\theta| Y)  = f(Y |\theta) \pi(\theta)$. \cite{toni2009abc}. The likelihood given here is not computable so that gave rise to new set of techniques that simulated the Bayesian inference by repeatedly sampling from some distribution accepting only samples  $\theta^*$ such that the simulated dataset is close to the original dataset $Y$. That way the output is sample from the posterior $\pi(\theta | Y)$. Generating a sample to simulate an unknown or difficult distribution is not a new technique as it is the main theme in traditional Monte Carlo techniques such as Metropolis-Hastings\cite{Walsh04markovchain}. Because computer simulation is more feasible nowadays these techniques commonly referred as Approximate Bayesian Computation techniques (approximate because they do not really do the Bayesian inference computation) have gained popularity. A range of different algorithms have been employed, from simple rejection samplers\cite{pritchard1999population} to Markov Chain Monte Carlo methods in the spirit of Metropolis-Hastings\cite{marjoram2003markov} and Sequential Monte Carlo methods which use a series of distributions that at every stage are closer to the true posterior\cite{toni2009abc}.\\
\noindent
\\
Tools that assist in the modeling process have been created in recent years(XPP-Auto, GRIND etc.). These tools are widely used because they allow modelers to get an intuition and greater understanding of the model in question usually by graphical means such as plotting bifurcation diagrams and allowing them to see the changes in the dynamics of the system as parameters change. And although they help in parameter estimation they do not address the problem directly. One other attempt that has been made that addresses the problem directly is the ABC-Sysbio\cite{liebe2010abcpy}. This tool does automatic parameter estimation using Sequential Monte Carlo method.\\
\noindent
\\
All these methods and these tools have as their main aim to find the set of parameters that reconstructs the experimental data. They do not take into account other features of the system in question that the model must capture to correctly capture its dynamics. However systems have a dynamic nature that has to be taken into account. They respond to signal in a certain way, they evolve. For example circadian oscillators that exist in many tissues get synchronised with the main clock in the SCM of the brain by getting an entrainment signal from it. When perturbed in that way their signal changes in a specific way as described by their Phase Response curves\cite{pfeuty2011robust}. Other studies have also been made in using Fourier Analysis which is a widely used technique in engineering applications to model selection by comparing the Fourier Transform as produced by different models with the Fourier Transform of the experimental data instead of actually comparing the data points of simulated versus real dataset\cite{konopka2010gene}. That way the model selection process captures other qualitative features of the model that are not directly observable from the data. Techniques from the rich topic of non-linear dynamical systems have been employed to look at the changes of dynamics of biological systems like how the inference process gets affected by the presence of Hopf bifurcations\cite{kirk2008parameter}. Another aspect of dynamic behaviour of such systems is captured by the changes in them when they go through the process of evolution. 
\section{Work}
\subsection{Results}

\section{Future Work}

\bibliography{progress}
\end{document}